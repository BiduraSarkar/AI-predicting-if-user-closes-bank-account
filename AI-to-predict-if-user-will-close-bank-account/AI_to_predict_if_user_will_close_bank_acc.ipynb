{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "FippShNqvcCG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVwrwudavuLF",
        "outputId": "87701fca-79d7-4879-ee6f-6eacc7753a6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Credit Score  Geography  Gender  Age  Customer Since  Current Account  \\\n",
            "0           553      Delhi  Female   45               4            0.000   \n",
            "1           447  Bengaluru    Male   31               7            0.000   \n",
            "2           501      Delhi  Female   32               2            0.000   \n",
            "3           428      Delhi    Male   51               3            0.000   \n",
            "4           492      Delhi  Female   57               6      1912681.501   \n",
            "\n",
            "   Num of products  UPI Enabled  Estimated Yearly Income  Closed  \n",
            "0                4            1                   274150       0  \n",
            "1                4            1                   519360       0  \n",
            "2                4            1                   545501       0  \n",
            "3                4            1                    86868       0  \n",
            "4                2            1                   518680       0  \n",
            "(9927, 10)\n",
            "Credit Score               0\n",
            "Geography                  0\n",
            "Gender                     0\n",
            "Age                        0\n",
            "Customer Since             0\n",
            "Current Account            0\n",
            "Num of products            0\n",
            "UPI Enabled                0\n",
            "Estimated Yearly Income    0\n",
            "Closed                     0\n",
            "dtype: int64\n",
            "Credit Score               0\n",
            "Geography                  0\n",
            "Gender                     0\n",
            "Age                        0\n",
            "Customer Since             0\n",
            "Current Account            0\n",
            "Num of products            0\n",
            "UPI Enabled                0\n",
            "Estimated Yearly Income    0\n",
            "Closed                     0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df =pd.read_csv('/content/American-Express-User-Exit-Pred.csv')\n",
        "print(df.head())\n",
        "print(df.shape)\n",
        "print(df.isnull().sum())\n",
        "df = df.interpolate()\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "qmFB4TOywbC4"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "le = LabelEncoder()\n",
        "df['Gender'] = le.fit_transform(df['Gender'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDgT1mAJxwpB",
        "outputId": "2c3a4e02-f9e7-42ef-9873-6ce208f4ad46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method NDFrame.describe of       Credit Score  Gender  Age  Customer Since  Current Account  \\\n",
            "0              553       0   45               4     0.000000e+00   \n",
            "1              447       1   31               7     0.000000e+00   \n",
            "2              501       0   32               2     0.000000e+00   \n",
            "3              428       1   51               3     0.000000e+00   \n",
            "4              492       0   57               6     1.912682e+06   \n",
            "...            ...     ...  ...             ...              ...   \n",
            "9922           594       1   28               6     0.000000e+00   \n",
            "9923           557       1   59               3     8.050490e+05   \n",
            "9924           627       0   42               4     1.893594e+06   \n",
            "9925           600       0   51               0     9.031778e+05   \n",
            "9926           553       1   75               7     0.000000e+00   \n",
            "\n",
            "      Num of products  UPI Enabled  Estimated Yearly Income  Closed  \\\n",
            "0                   4            1                   274150       0   \n",
            "1                   4            1                   519360       0   \n",
            "2                   4            1                   545501       0   \n",
            "3                   4            1                    86868       0   \n",
            "4                   2            1                   518680       0   \n",
            "...               ...          ...                      ...     ...   \n",
            "9922                4            1                   394810       0   \n",
            "9923                2            0                    58163       1   \n",
            "9924                4            0                   494067       0   \n",
            "9925                2            1                   109375       1   \n",
            "9926                4            1                   180031       0   \n",
            "\n",
            "      Geography_Bengaluru  Geography_Delhi  Geography_Mumbai  \n",
            "0                     0.0              1.0               0.0  \n",
            "1                     1.0              0.0               0.0  \n",
            "2                     0.0              1.0               0.0  \n",
            "3                     0.0              1.0               0.0  \n",
            "4                     0.0              1.0               0.0  \n",
            "...                   ...              ...               ...  \n",
            "9922                  1.0              0.0               0.0  \n",
            "9923                  1.0              0.0               0.0  \n",
            "9924                  0.0              0.0               1.0  \n",
            "9925                  1.0              0.0               0.0  \n",
            "9926                  0.0              1.0               0.0  \n",
            "\n",
            "[9927 rows x 12 columns]>\n"
          ]
        }
      ],
      "source": [
        "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "one_hot_encoded = encoder.fit_transform(df[categorical_columns])\n",
        "one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(categorical_columns))\n",
        "df_encoded = pd.concat([df, one_hot_df], axis=1)\n",
        "df = df_encoded.drop(categorical_columns, axis=1)\n",
        "print(df.describe)\n",
        "X = df.iloc[:,:-1]\n",
        "y= df.iloc[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "bU0h0QO6zzUj"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "J3-wBHoh0frj"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler =  StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "vWMeMDNh1qpL"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(units=5,activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(units=5,activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "IIzKAFKg2l5Y"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',metrics=['accuracy'],loss='binary_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD2Xq11x3h-y",
        "outputId": "afd91dea-c0f8-419f-9980-6675a9052f7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.4917 - accuracy: 0.8331\n",
            "Epoch 2/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 0.1448 - accuracy: 0.9962\n",
            "Epoch 3/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 1.0000\n",
            "Epoch 4/120\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.0108 - accuracy: 1.0000\n",
            "Epoch 5/120\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 6/120\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 7/120\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 8/120\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 9/120\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 8.9442e-04 - accuracy: 1.0000\n",
            "Epoch 10/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 6.6442e-04 - accuracy: 1.0000\n",
            "Epoch 11/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 5.0605e-04 - accuracy: 1.0000\n",
            "Epoch 12/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 3.9361e-04 - accuracy: 1.0000\n",
            "Epoch 13/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 3.1133e-04 - accuracy: 1.0000\n",
            "Epoch 14/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 2.4953e-04 - accuracy: 1.0000\n",
            "Epoch 15/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 2.0226e-04 - accuracy: 1.0000\n",
            "Epoch 16/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.6545e-04 - accuracy: 1.0000\n",
            "Epoch 17/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.3641e-04 - accuracy: 1.0000\n",
            "Epoch 18/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.1319e-04 - accuracy: 1.0000\n",
            "Epoch 19/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 9.4378e-05 - accuracy: 1.0000\n",
            "Epoch 20/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 7.9081e-05 - accuracy: 1.0000\n",
            "Epoch 21/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 6.6513e-05 - accuracy: 1.0000\n",
            "Epoch 22/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 5.6149e-05 - accuracy: 1.0000\n",
            "Epoch 23/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 4.7538e-05 - accuracy: 1.0000\n",
            "Epoch 24/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 4.0323e-05 - accuracy: 1.0000\n",
            "Epoch 25/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 3.4328e-05 - accuracy: 1.0000\n",
            "Epoch 26/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 2.9285e-05 - accuracy: 1.0000\n",
            "Epoch 27/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 2.5016e-05 - accuracy: 1.0000\n",
            "Epoch 28/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 2.1409e-05 - accuracy: 1.0000\n",
            "Epoch 29/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.8348e-05 - accuracy: 1.0000\n",
            "Epoch 30/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.5742e-05 - accuracy: 1.0000\n",
            "Epoch 31/120\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 1.3530e-05 - accuracy: 1.0000\n",
            "Epoch 32/120\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 1.1638e-05 - accuracy: 1.0000\n",
            "Epoch 33/120\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 1.0023e-05 - accuracy: 1.0000\n",
            "Epoch 34/120\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 8.6346e-06 - accuracy: 1.0000\n",
            "Epoch 35/120\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 7.4503e-06 - accuracy: 1.0000\n",
            "Epoch 36/120\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 6.4323e-06 - accuracy: 1.0000\n",
            "Epoch 37/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 5.5593e-06 - accuracy: 1.0000\n",
            "Epoch 38/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 4.8079e-06 - accuracy: 1.0000\n",
            "Epoch 39/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 4.1615e-06 - accuracy: 1.0000\n",
            "Epoch 40/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 3.6015e-06 - accuracy: 1.0000\n",
            "Epoch 41/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 3.1191e-06 - accuracy: 1.0000\n",
            "Epoch 42/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 2.7020e-06 - accuracy: 1.0000\n",
            "Epoch 43/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 2.3411e-06 - accuracy: 1.0000\n",
            "Epoch 44/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 2.0281e-06 - accuracy: 1.0000\n",
            "Epoch 45/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.7596e-06 - accuracy: 1.0000\n",
            "Epoch 46/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.5262e-06 - accuracy: 1.0000\n",
            "Epoch 47/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.3245e-06 - accuracy: 1.0000\n",
            "Epoch 48/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.1499e-06 - accuracy: 1.0000\n",
            "Epoch 49/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 9.9837e-07 - accuracy: 1.0000\n",
            "Epoch 50/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 8.6741e-07 - accuracy: 1.0000\n",
            "Epoch 51/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 7.5384e-07 - accuracy: 1.0000\n",
            "Epoch 52/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 6.5485e-07 - accuracy: 1.0000\n",
            "Epoch 53/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 5.6977e-07 - accuracy: 1.0000\n",
            "Epoch 54/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 4.9556e-07 - accuracy: 1.0000\n",
            "Epoch 55/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 4.3119e-07 - accuracy: 1.0000\n",
            "Epoch 56/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 3.7534e-07 - accuracy: 1.0000\n",
            "Epoch 57/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 3.2674e-07 - accuracy: 1.0000\n",
            "Epoch 58/120\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 2.8434e-07 - accuracy: 1.0000\n",
            "Epoch 59/120\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 2.4765e-07 - accuracy: 1.0000\n",
            "Epoch 60/120\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 2.1563e-07 - accuracy: 1.0000\n",
            "Epoch 61/120\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 1.8784e-07 - accuracy: 1.0000\n",
            "Epoch 62/120\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 1.6366e-07 - accuracy: 1.0000\n",
            "Epoch 63/120\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 1.4267e-07 - accuracy: 1.0000\n",
            "Epoch 64/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.2442e-07 - accuracy: 1.0000\n",
            "Epoch 65/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.0853e-07 - accuracy: 1.0000\n",
            "Epoch 66/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 9.4702e-08 - accuracy: 1.0000\n",
            "Epoch 67/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 8.2708e-08 - accuracy: 1.0000\n",
            "Epoch 68/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 7.2258e-08 - accuracy: 1.0000\n",
            "Epoch 69/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 6.3147e-08 - accuracy: 1.0000\n",
            "Epoch 70/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 5.5241e-08 - accuracy: 1.0000\n",
            "Epoch 71/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 4.8346e-08 - accuracy: 1.0000\n",
            "Epoch 72/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 4.2356e-08 - accuracy: 1.0000\n",
            "Epoch 73/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 3.7152e-08 - accuracy: 1.0000\n",
            "Epoch 74/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 3.2618e-08 - accuracy: 1.0000\n",
            "Epoch 75/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 2.8642e-08 - accuracy: 1.0000\n",
            "Epoch 76/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 2.5176e-08 - accuracy: 1.0000\n",
            "Epoch 77/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 2.2172e-08 - accuracy: 1.0000\n",
            "Epoch 78/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.9542e-08 - accuracy: 1.0000\n",
            "Epoch 79/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.7253e-08 - accuracy: 1.0000\n",
            "Epoch 80/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.5257e-08 - accuracy: 1.0000\n",
            "Epoch 81/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.3511e-08 - accuracy: 1.0000\n",
            "Epoch 82/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.1968e-08 - accuracy: 1.0000\n",
            "Epoch 83/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.0615e-08 - accuracy: 1.0000\n",
            "Epoch 84/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 9.4374e-09 - accuracy: 1.0000\n",
            "Epoch 85/120\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 8.4026e-09 - accuracy: 1.0000\n",
            "Epoch 86/120\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 7.4839e-09 - accuracy: 1.0000\n",
            "Epoch 87/120\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 6.6709e-09 - accuracy: 1.0000\n",
            "Epoch 88/120\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 5.9828e-09 - accuracy: 1.0000\n",
            "Epoch 89/120\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 5.3562e-09 - accuracy: 1.0000\n",
            "Epoch 90/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 4.8159e-09 - accuracy: 1.0000\n",
            "Epoch 91/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 4.3185e-09 - accuracy: 1.0000\n",
            "Epoch 92/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 3.8946e-09 - accuracy: 1.0000\n",
            "Epoch 93/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 3.5087e-09 - accuracy: 1.0000\n",
            "Epoch 94/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 3.1810e-09 - accuracy: 1.0000\n",
            "Epoch 95/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 2.8891e-09 - accuracy: 1.0000\n",
            "Epoch 96/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 2.6082e-09 - accuracy: 1.0000\n",
            "Epoch 97/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 2.3788e-09 - accuracy: 1.0000\n",
            "Epoch 98/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 2.1768e-09 - accuracy: 1.0000\n",
            "Epoch 99/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.9890e-09 - accuracy: 1.0000\n",
            "Epoch 100/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.8311e-09 - accuracy: 1.0000\n",
            "Epoch 101/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.6898e-09 - accuracy: 1.0000\n",
            "Epoch 102/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.5684e-09 - accuracy: 1.0000\n",
            "Epoch 103/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.4554e-09 - accuracy: 1.0000\n",
            "Epoch 104/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.3323e-09 - accuracy: 1.0000\n",
            "Epoch 105/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.2433e-09 - accuracy: 1.0000\n",
            "Epoch 106/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.1590e-09 - accuracy: 1.0000\n",
            "Epoch 107/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.0962e-09 - accuracy: 1.0000\n",
            "Epoch 108/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 1.0323e-09 - accuracy: 1.0000\n",
            "Epoch 109/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 9.7997e-10 - accuracy: 1.0000\n",
            "Epoch 110/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 9.2407e-10 - accuracy: 1.0000\n",
            "Epoch 111/120\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 8.7228e-10 - accuracy: 1.0000\n",
            "Epoch 112/120\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 8.3239e-10 - accuracy: 1.0000\n",
            "Epoch 113/120\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 7.9173e-10 - accuracy: 1.0000\n",
            "Epoch 114/120\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 7.6348e-10 - accuracy: 1.0000\n",
            "Epoch 115/120\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 7.3039e-10 - accuracy: 1.0000\n",
            "Epoch 116/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 7.0694e-10 - accuracy: 1.0000\n",
            "Epoch 117/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 6.8114e-10 - accuracy: 1.0000\n",
            "Epoch 118/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 6.5769e-10 - accuracy: 1.0000\n",
            "Epoch 119/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 6.3694e-10 - accuracy: 1.0000\n",
            "Epoch 120/120\n",
            "249/249 [==============================] - 0s 2ms/step - loss: 6.1281e-10 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d5ba11224a0>"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ],
      "source": [
        "model.fit(X_train,y_train,batch_size=32,epochs=120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRFIwIn46J6s",
        "outputId": "d9841645-7b04-4676-d471-aace80128765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SIcoIc18LO7",
        "outputId": "a9466e04-c3f3-49ad-97cc-c092beeeba0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1464    0]\n",
            " [   0  522]]\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "print(cm)\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(precision_score(y_test,y_pred))\n",
        "print(recall_score(y_test,y_pred))\n",
        "print(f1_score(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "4XTY4kaC8UIq"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train,y_train)\n",
        "y_pred2 = lr.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test,y_pred2)\n",
        "print(cm)\n",
        "print(accuracy_score(y_test,y_pred2))\n",
        "print(precision_score(y_test,y_pred2))\n",
        "print(recall_score(y_test,y_pred2))\n",
        "print(f1_score(y_test,y_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0bjBYn7CzUP",
        "outputId": "a3a6cef6-b3c7-41e5-c50b-23919f2263b3"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1464    0]\n",
            " [   0  522]]\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "1.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}